{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfuSvY4viDoT"
      },
      "outputs": [],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6x6Sc5V0xNi"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XywZDL37sv_"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import csv\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF0xMu345vqK"
      },
      "outputs": [],
      "source": [
        "dataset = open('claim_reviews_en.csv')\n",
        "myReader = csv.reader(dataset)\n",
        "\n",
        "#Our sentences we like to encode\n",
        "sentences = []\n",
        "line = 0\n",
        "for row in myReader:\n",
        "  if line != 0:\n",
        "    sentences.append(row[0])\n",
        "  line = line + 1\n",
        "\n",
        "#sentences = sentences[0:10]\n",
        "\n",
        "#Sentences are encoded by calling model.encode()\n",
        "#embeddings = model.encode(sentences)\n",
        "\n",
        "#Print the embeddings\n",
        "#for sentence, embedding in zip(sentences, embeddings):\n",
        "#    print(\"Sentence:\", sentence)\n",
        "#    print(\"Embedding:\", embedding)\n",
        "#    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5_tDfgHS0Ac"
      },
      "source": [
        "# Syntax similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P-6rL-ldcLl"
      },
      "source": [
        "## Importations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m21XrG3Uaeu",
        "outputId": "f25226c9-620a-4386-d547-572f23717dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy import displacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jq15G-Pdfhm"
      },
      "source": [
        "## Variables de travail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k31tC0qZHAh"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "dataset = open('claim_reviews_en.csv')\n",
        "myReader = csv.reader(dataset)\n",
        "\n",
        "#Our sentences we like to encode\n",
        "sentences = []\n",
        "line = 0\n",
        "for row in myReader:\n",
        "  if line != 0:\n",
        "    sentences.append(row[0])\n",
        "  line = line + 1\n",
        "\n",
        "tagsList = [\"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CCONJ\", \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \"PART\", \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\"]\n",
        "pattern = 'Clara Lina Éloïse'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf8d-dlRdwEj"
      },
      "source": [
        "## Fonction pour convertir un POS tag en entier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUKxG4rmZ8C_"
      },
      "outputs": [],
      "source": [
        "def tagToIntetger(tag):\n",
        "  n = len(tagsList)\n",
        "  for i in range(n):\n",
        "    if tag == tagsList[i]:\n",
        "      return i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej8ciEDUdah7"
      },
      "source": [
        "## Transformation des phrases en vecteurs de POS tags puis en vecteurs d'entiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHDiZ50JS8cg"
      },
      "outputs": [],
      "source": [
        "## Rq: exécution 6'\n",
        "\n",
        "#sentences = sentences[0:5]\n",
        "sentencesToken = []\n",
        "\n",
        "for s in sentences:\n",
        "  t = []\n",
        "  doc = nlp(s)\n",
        "  for token in doc:\n",
        "    t.append(tagToIntetger(token.pos_))\n",
        "  sentencesToken.append(t)\n",
        "\n",
        "patternToken = []\n",
        "doc = nlp(pattern)\n",
        "for token in doc:\n",
        "  patternToken.append(tagToIntetger(token.pos_))\n",
        "\n",
        "#for i in range(5):\n",
        "#  print(sentences[i])\n",
        "#  print(sentencesToken[i])\n",
        "\n",
        "#print('')\n",
        "#print(pattern)\n",
        "#print(patternToken)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c21hOrrXeSU5"
      },
      "source": [
        "## Recherche du pattern dans les phrases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwCidFxgqKb"
      },
      "source": [
        "On a un motif de 3 mots que l'on recherche n'importe où dans les phrases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvFiAVLBwOwR"
      },
      "outputs": [],
      "source": [
        "strongPattern1 = \"Lola said that\"\n",
        "strongPattern2 = 'Lola said \"'\n",
        "\n",
        "patternToken1 = []\n",
        "doc = nlp(strongPattern1)\n",
        "for token in doc:\n",
        "  patternToken1.append(tagToIntetger(token.pos_))\n",
        "\n",
        "patternToken2 = []\n",
        "doc = nlp(strongPattern2)\n",
        "for token in doc:\n",
        "  patternToken2.append(tagToIntetger(token.pos_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrgeBFUceiTR"
      },
      "outputs": [],
      "source": [
        "index = -1\n",
        "\n",
        "for v in sentencesToken:\n",
        "  index = index + 1\n",
        "  n = len(v)\n",
        "  for i in range(n-2):\n",
        "    if v[i] == patternToken[0]:\n",
        "      if v[i+1] == patternToken[1]:\n",
        "        if v[i+2] == patternToken[2]:\n",
        "          #print(nlp(sentences[index])[i:i+3])\n",
        "          x=0\n",
        "\n",
        "print('')\n",
        "index = -1\n",
        "\n",
        "for v in sentencesToken:\n",
        "  index = index + 1\n",
        "  n = len(v)\n",
        "  for i in range(n-2):\n",
        "    if v[i] == patternToken1[0]:\n",
        "      if v[i+1] == patternToken1[1]:\n",
        "        if v[i+2] == patternToken1[2]:\n",
        "          print(nlp(sentences[index])[i:i+3])\n",
        "\n",
        "index = -1\n",
        "\n",
        "for v in sentencesToken:\n",
        "  index = index + 1\n",
        "  n = len(v)\n",
        "  for i in range(n-2):\n",
        "    if v[i] == patternToken2[0]:\n",
        "      if v[i+1] == patternToken2[1]:\n",
        "        if v[i+2] == patternToken2[2]:\n",
        "          print(nlp(sentences[index])[i:i+3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtsG1T_g1SSX"
      },
      "source": [
        "Ici on veut comparer une phrase avec un TAG à la fois.\n",
        "\n",
        "On va commencer par choisir un TAG et chercher combien sont présents dans la phrase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUbGVjZJ1DCr"
      },
      "outputs": [],
      "source": [
        "def countTAG(tag, sToken):\n",
        "  intValue = tagToIntetger(tag)\n",
        "  nb = 0\n",
        "  for i in sToken:\n",
        "    if i == intValue:\n",
        "      nb = nb+1\n",
        "  return nb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIC7Stx-6W6E"
      },
      "outputs": [],
      "source": [
        "def tagsVector(sToken):\n",
        "  v = []\n",
        "  for tag in tagsList:\n",
        "    v.append(countTAG(tag, sToken))\n",
        "  return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd8CMpTr7XKK"
      },
      "outputs": [],
      "source": [
        "def diff(sToken1, sToken2):\n",
        "  v1, v2 = tagsVector(sToken1), tagsVector(sToken2)\n",
        "  diff = [abs(v1[i]-v2[i]) for i in range(17)]\n",
        "  diff[7], diff[15] = 2*diff[7], 2*diff[15]\n",
        "  dist = 0\n",
        "  for i in diff:\n",
        "    dist = dist + i\n",
        "  dist = float(dist/(len(diff)+2))\n",
        "  return dist\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5gFA2xJ15tl"
      },
      "source": [
        "Cherchons les phrases les plus ressemblantes à la première."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNRl0aX914_M"
      },
      "outputs": [],
      "source": [
        "n = len(sentencesToken)\n",
        "first_sentence = sentencesToken[0]\n",
        "scores = {sentences[0]:0}\n",
        "for i in range(1,n):\n",
        "  scores[sentences[i]] = diff(sentencesToken[i],first_sentence)\n",
        "\n",
        "scores = sorted(scores.items(), key=lambda t: t[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCXwjyKE_MdU",
        "outputId": "fe106853-bbb5-4fac-f026-19ecf57c788f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('A blog site publication stated that the President fired his Chief of Staff, further appointing Ajimobi as a replacement.', 0.15789473684210525)\n"
          ]
        }
      ],
      "source": [
        "print(scores[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9N6XAo9vP9B"
      },
      "source": [
        "On veut continuer à prendre en compte la position des mots.\n",
        "\n",
        "On peut découper les phrases en petits pattern et chercher les ressemblances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAGxMbIb1zkJ"
      },
      "source": [
        "On cherche si deux phrases ont des pattern en commun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EXOAeJi1y4a"
      },
      "outputs": [],
      "source": [
        "def commonPatterns(s1, s2):\n",
        "  nb = 0\n",
        "\n",
        "  n1, n2 = len(s1), len(s2)\n",
        "  p1, p2 = [], []\n",
        "  for i in range(n1-2):\n",
        "    p1.append(s1[i:i+3])\n",
        "  for i in range(n2-2):\n",
        "    p2.append(s2[i:i+3])\n",
        "\n",
        "  n1, n2 = len(p1), len(p2)\n",
        "  for i in range(n1):\n",
        "    p = p1[i]\n",
        "    for k in range(n2):\n",
        "      if p == p2[k]:\n",
        "        nb = nb+1\n",
        "  return nb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FUfaafbPueO",
        "outputId": "3bb55191-16ce-4bc1-bc5d-1051e0fbaa01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "print(commonPatterns(sentencesToken[0], sentencesToken[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXkAgRmdvPhR"
      },
      "outputs": [],
      "source": [
        "n = len(sentencesToken)\n",
        "\n",
        "for i in range(n):\n",
        "  for k in range(i+1,n):\n",
        "    #print(\"Score between \", sentences[i], \" and \", sentences[k], \" = \", commonPatterns(sentencesToken[i], sentencesToken[k]))\n",
        "    score = commonPatterns(sentencesToken[i], sentencesToken[k])\n",
        "    if score >= 50:\n",
        "      print(\"Sentence 1 = \", sentences[i])\n",
        "      print(\"Sentence 2 = \", sentences[k])\n",
        "      print(\"Score: \", score)\n",
        "      print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYsR6qKU3T1m",
        "outputId": "f6fcedec-3ada-403e-c658-63277a0d02e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ratan Tata Says, If The Death Of 65 Soldiers Increases The Popularity Of A Prime Minister, Then Nobody Can Save This Country\n",
            "[11, 11, 15, 12, 13, 5, 7, 1, 8, 7, 15, 5, 7, 1, 5, 11, 11, 12, 2, 10, 3, 15, 5, 7]\n"
          ]
        }
      ],
      "source": [
        "# TESTS\n",
        "\n",
        "print(sentences[0])\n",
        "print(sentencesToken[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INR68Mj7zeS-"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open ( \"pos_similarities_examples.pickle\", \"rb\" ) as f:\n",
        "    idxs = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojrTdGA50l4H",
        "outputId": "ed1d2284-21d2-4797-c9a1-5c628f6ea534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[46304, 26590, 34527, 1086, 8928, 13250, 9224, 10638, 37749, 6698, 25043, 7950, 38097, 24932, 18536, 21229, 16509, 42001, 13103, 1614, 13492, 22699, 7911, 13591, 28630, 33939, 1454, 2370, 12583, 30012, 6524, 1742, 11918, 36433, 24428, 18680, 39172, 9882, 44833, 35635, 14901, 9002, 217, 19501, 12728, 16976, 33281, 36175, 35940, 18690, 1620, 21596, 34292, 34550, 42763, 33625, 18693, 8603, 6343, 14632, 39500, 23843, 15740, 23980, 1250, 46644, 33195, 19205, 34157, 28789, 36324, 6672, 9465, 46784, 5401, 1963, 37092, 23555, 8429, 21604, 8104, 34816, 25117, 23151, 8007, 11268, 36141, 35972, 4395, 27252, 7915, 1980, 17970, 36208, 32851, 15182, 45530, 24986, 5224, 6740]\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "print (idxs)\n",
        "print(len(idxs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rfheet7t1Kxz"
      },
      "outputs": [],
      "source": [
        "n = len(sentencesToken)\n",
        "scoreMatrix = [[] for _ in range(len(idxs))]\n",
        "line = 0\n",
        "\n",
        "for i in idxs:\n",
        "  scoreMatrix[line].append((i,sentences[i],0))\n",
        "  for k in range(n):\n",
        "    if k not in idxs:\n",
        "      score = commonPatterns(sentencesToken[i], sentencesToken[k])\n",
        "      scoreMatrix[line].append((k,sentences[k],score))\n",
        "  line = line+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ww8e1xw5imv",
        "outputId": "bf0f338a-8d8c-4ba9-f435-271d0a8a5ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Ratan Tata Says, If The Death Of 65 Soldiers Increases The Popularity Of A Prime Minister, Then Nobody Can Save This Country', 0)\n"
          ]
        }
      ],
      "source": [
        "print (scoreMatrix[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMN8W8-fCb0p"
      },
      "outputs": [],
      "source": [
        "with open ( \"similarity_matrix_cpn.pkl\", \"wb\" ) as f:\n",
        "    pickle.dump( scoreMatrix, f )"
      ]
    }
  ]
}